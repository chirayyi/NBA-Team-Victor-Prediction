{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import ast\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api call imports\n",
    "from nba_api.stats.endpoints import teamplayerdashboard\n",
    "from nba_api.stats.library.parameters import SeasonAll\n",
    "from nba_api.stats.static import teams, players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building imports\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player df\n",
    "dfp = pd.read_csv(\"./data/full_team_player_v2.csv\")\n",
    "\n",
    "# team df\n",
    "dft = pd.read_csv(\"./data/full_teams_data.csv\")\n",
    "\n",
    "# team roster df\n",
    "dfr = pd.read_csv(\"./data/team_rosters.csv\")\n",
    "dfr = dfr.set_index([\"TEAM\", \"SEASON\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregation data\n",
    "wpdf = pd.read_csv(\"./data/full_team_player_v3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_win_pct_pred_data(wpdf):\n",
    "    bins = []\n",
    "    for x in wpdf[\"W_PCT\"]:\n",
    "        if x >= 0.5:\n",
    "            bins.append(1)\n",
    "        else:\n",
    "            bins.append(0)\n",
    "    \n",
    "    wpdf[\"W_PCT_BIN\"] = bins\n",
    "    \n",
    "    return wpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_win_pct(wpdf, season, num_prev_seasons, classify=True):\n",
    "    if season == '2013-14':\n",
    "        print(\"Can't test 2013 data since there is no data before this season.\")\n",
    "        return \"\"\n",
    "    \n",
    "    seasons = wpdf[\"GROUP_VALUE\"].unique().tolist()\n",
    "    indexed_season = seasons.index(season)\n",
    "    start_season_index = indexed_season-num_prev_seasons\n",
    "    if start_season_index < 0:\n",
    "        start_season_index = 0\n",
    "    training_seasons = seasons[start_season_index:indexed_season]\n",
    "    print(training_seasons)\n",
    "    \n",
    "    X_cont = wpdf.columns[7:-1]\n",
    "    X = X_cont\n",
    "#     X = []\n",
    "#     for col in X_cont:\n",
    "#         for season in training_seasons:\n",
    "#             print(col, season)\n",
    "#             if col.endswith(season):\n",
    "#                 X.append(col)\n",
    "                \n",
    "#     print(X)\n",
    "                \n",
    "    if classify:\n",
    "        Y = ['W_PCT_BIN']\n",
    "    else:\n",
    "        Y = ['W_PCT']\n",
    "        \n",
    "    # get previous season data (training)\n",
    "    train_data = wpdf[wpdf[\"GROUP_VALUE\"].isin(training_seasons)]\n",
    "    X_train = train_data[X].fillna(0)\n",
    "    Y_train = train_data[Y]\n",
    "    \n",
    "    #get current season data (testing)\n",
    "    test_data = wpdf[wpdf[\"GROUP_VALUE\"] == season]\n",
    "    X_test = test_data[X].fillna(0)\n",
    "    Y_test = test_data[Y]\n",
    "    \n",
    "    # standardize data\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # choose hyperparameters\n",
    "    n_estimators = 12\n",
    "    depth = 19\n",
    "    \n",
    "    #f1metrics = {}\n",
    "    #for n_estimators in range(5, 25):\n",
    "    #    f2metrics = {}\n",
    "    #    for depth in range(10, 25):\n",
    "    #        print(\"{}:{} > \".format(n_estimators, depth), end=\"\")\n",
    "    if classify:\n",
    "        accs = []\n",
    "        for _ in range(200):\n",
    "            mod = RandomForestClassifier(n_estimators=n_estimators, max_depth=depth).fit(X_train, Y_train)\n",
    "            preds = mod.predict(X_test)\n",
    "            accs.append(accuracy_score(Y_test, preds))\n",
    "            \n",
    "        return sum(accs)/len(accs)\n",
    "        #f2metrics[depth] = sum(accs)/len(accs)\n",
    "    else:\n",
    "        maes = []\n",
    "        for _ in range(200):\n",
    "            mod = RandomForestRegressor(n_estimators=n_estimators, max_depth=depth).fit(X_train, Y_train)\n",
    "            preds = mod.predict(X_test)\n",
    "            maes.append(mean_absolute_error(Y_test, preds))\n",
    "#             f2metrics[depth] = sum(maes)/len(maes)\n",
    "        return sum(maes)/len(maes)\n",
    "        \n",
    "#     f1metrics[n_estimators] = f2metrics\n",
    "    \n",
    "#     return f1metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpdf = prep_win_pct_pred_data(wpdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 323)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Model Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2014-15', '2015-16', '2016-17', '2017-18']\n"
     ]
    }
   ],
   "source": [
    "metrics = predict_win_pct(wpdf, '2018-19', 4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5819999999999995"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for predicting 2018-19 season games and looking back 4 seasons\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some other adiditonal tests that you can run. \n",
    "Pass in the dataset (wpdf), the current season, the number of previous seasons you want to train on, and whether you want to classify (True) or predict with regression (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015-16', '2016-17', '2017-18', '2018-19']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6163333333333337"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_win_pct(wpdf, '2019-20', 4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2013-14', '2014-15', '2015-16']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6818333333333341"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_win_pct(wpdf, '2016-17', 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017-18']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6375000000000012"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_win_pct(wpdf, '2018-19', 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate Model Against All Seasons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training season 2013-14, looking back 1 seasons...\n",
      "Can't test 2013 data since there is no data before this season.\n",
      "Training season 2013-14, looking back 2 seasons...\n",
      "Can't test 2013 data since there is no data before this season.\n",
      "Training season 2013-14, looking back 3 seasons...\n",
      "Can't test 2013 data since there is no data before this season.\n",
      "Training season 2013-14, looking back 4 seasons...\n",
      "Can't test 2013 data since there is no data before this season.\n",
      "Training season 2013-14, looking back 5 seasons...\n",
      "Can't test 2013 data since there is no data before this season.\n",
      "Training season 2014-15, looking back 1 seasons...\n",
      "['2013-14']\n",
      "Training season 2014-15, looking back 2 seasons...\n",
      "['2013-14']\n",
      "Training season 2014-15, looking back 3 seasons...\n",
      "['2013-14']\n",
      "Training season 2014-15, looking back 4 seasons...\n",
      "['2013-14']\n",
      "Training season 2014-15, looking back 5 seasons...\n",
      "['2013-14']\n",
      "Training season 2015-16, looking back 1 seasons...\n",
      "['2014-15']\n",
      "Training season 2015-16, looking back 2 seasons...\n",
      "['2013-14', '2014-15']\n",
      "Training season 2015-16, looking back 3 seasons...\n",
      "['2013-14', '2014-15']\n",
      "Training season 2015-16, looking back 4 seasons...\n",
      "['2013-14', '2014-15']\n",
      "Training season 2015-16, looking back 5 seasons...\n",
      "['2013-14', '2014-15']\n",
      "Training season 2016-17, looking back 1 seasons...\n",
      "['2015-16']\n",
      "Training season 2016-17, looking back 2 seasons...\n",
      "['2014-15', '2015-16']\n",
      "Training season 2016-17, looking back 3 seasons...\n",
      "['2013-14', '2014-15', '2015-16']\n",
      "Training season 2016-17, looking back 4 seasons...\n",
      "['2013-14', '2014-15', '2015-16']\n",
      "Training season 2016-17, looking back 5 seasons...\n",
      "['2013-14', '2014-15', '2015-16']\n",
      "Training season 2017-18, looking back 1 seasons...\n",
      "['2016-17']\n",
      "Training season 2017-18, looking back 2 seasons...\n",
      "['2015-16', '2016-17']\n",
      "Training season 2017-18, looking back 3 seasons...\n",
      "['2014-15', '2015-16', '2016-17']\n",
      "Training season 2017-18, looking back 4 seasons...\n",
      "['2013-14', '2014-15', '2015-16', '2016-17']\n",
      "Training season 2017-18, looking back 5 seasons...\n",
      "['2013-14', '2014-15', '2015-16', '2016-17']\n",
      "Training season 2018-19, looking back 1 seasons...\n",
      "['2017-18']\n",
      "Training season 2018-19, looking back 2 seasons...\n",
      "['2016-17', '2017-18']\n",
      "Training season 2018-19, looking back 3 seasons...\n",
      "['2015-16', '2016-17', '2017-18']\n",
      "Training season 2018-19, looking back 4 seasons...\n",
      "['2014-15', '2015-16', '2016-17', '2017-18']\n",
      "Training season 2018-19, looking back 5 seasons...\n",
      "['2013-14', '2014-15', '2015-16', '2016-17', '2017-18']\n",
      "Training season 2019-20, looking back 1 seasons...\n",
      "['2018-19']\n",
      "Training season 2019-20, looking back 2 seasons...\n",
      "['2017-18', '2018-19']\n",
      "Training season 2019-20, looking back 3 seasons...\n",
      "['2016-17', '2017-18', '2018-19']\n",
      "Training season 2019-20, looking back 4 seasons...\n",
      "['2015-16', '2016-17', '2017-18', '2018-19']\n",
      "Training season 2019-20, looking back 5 seasons...\n",
      "['2014-15', '2015-16', '2016-17', '2017-18', '2018-19']\n"
     ]
    }
   ],
   "source": [
    "# runs through all seasons and training with 1-6 prior seasons \n",
    "# change this variable to FALSE to conduct regression prediction and TRUE for classification prediction\n",
    "classification = True\n",
    "\n",
    "metrics_seasonal = {}\n",
    "for season in wpdf[\"GROUP_VALUE\"].unique().tolist():\n",
    "    num_prev_seasons_dict = {}\n",
    "    for num_prev_seasons in range(1, 6):\n",
    "        print(\"Training season {}, looking back {} seasons...\".format(season, num_prev_seasons))\n",
    "        num_prev_seasons_dict[num_prev_seasons] = predict_win_pct(wpdf, season, num_prev_seasons, classification)\n",
    "    metrics_seasonal[season] = num_prev_seasons_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2013-14': {1: '', 2: '', 3: '', 4: '', 5: ''},\n",
       " '2014-15': {1: 0.6585000000000008,\n",
       "  2: 0.6530000000000006,\n",
       "  3: 0.6500000000000006,\n",
       "  4: 0.6595000000000008,\n",
       "  5: 0.6505000000000005},\n",
       " '2015-16': {1: 0.7795000000000004,\n",
       "  2: 0.7536666666666669,\n",
       "  3: 0.755666666666667,\n",
       "  4: 0.7593333333333331,\n",
       "  5: 0.7634999999999996},\n",
       " '2016-17': {1: 0.6980000000000004,\n",
       "  2: 0.6868333333333341,\n",
       "  3: 0.6796666666666675,\n",
       "  4: 0.6813333333333341,\n",
       "  5: 0.6865000000000008},\n",
       " '2017-18': {1: 0.7581666666666669,\n",
       "  2: 0.6976666666666668,\n",
       "  3: 0.6731666666666674,\n",
       "  4: 0.6630000000000011,\n",
       "  5: 0.6650000000000003},\n",
       " '2018-19': {1: 0.6390000000000009,\n",
       "  2: 0.6285000000000006,\n",
       "  3: 0.5844999999999996,\n",
       "  4: 0.5811666666666664,\n",
       "  5: 0.5848333333333334},\n",
       " '2019-20': {1: 0.6178333333333335,\n",
       "  2: 0.5945000000000004,\n",
       "  3: 0.5676666666666664,\n",
       "  4: 0.6153333333333336,\n",
       "  5: 0.6038333333333337}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy by current season & # of prior seasons looked at\n",
    "metrics_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save metrics output to pickle file\n",
    "if classification:\n",
    "    output_type = \"classification\" \n",
    "else:\n",
    "    output_type = \"regression\"\n",
    "with open(\"./results/metrics_seasonal_{}.pkl\".format(output_type), \"wb\") as file:\n",
    "    pickle.dump(metrics_seasonal, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy By Season**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = wpdf[\"GROUP_VALUE\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-15\n",
      "0.48758089941582583\n",
      "2015-16\n",
      "0.5782554377812922\n",
      "2016-17\n",
      "0.6730983793649054\n",
      "2017-18\n",
      "0.5304743320639487\n",
      "2018-19\n",
      "0.42753005733794813\n",
      "2019-20\n",
      "0.16263684010747761\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(seasons)):\n",
    "    print(seasons[i])\n",
    "    sdf = wpdf[wpdf[\"GROUP_VALUE\"] == seasons[i]]\n",
    "    print(sdf[\"W_PCT\"].corr(sdf[\"FGM_{}\".format(seasons[i-1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Win/Loss Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwl = pd.read_csv(\"./data/nba_player_data_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_winloss_data(df, seasons):\n",
    "    print(\"Prepping\", df.shape, \"...\")\n",
    "    df[\"GAME_DATE\"] = pd.to_datetime(df[\"GAME_DATE\"])\n",
    "    df[\"SEASON_ID\"] = df[\"SEASON_ID\"].apply(lambda x: str(x)[1:]+'-'+str(int(str(x)[1:][-2:])+1))\n",
    "    df = df[df[\"SEASON_ID\"].isin(seasons)]\n",
    "    \n",
    "    # get week num id\n",
    "    df[\"GAME_WEEK\"] = df[\"GAME_DATE\"].dt.week\n",
    "    \n",
    "    players_dict = players.get_players()\n",
    "    \n",
    "    players_list = []\n",
    "    for player_id in df[\"Player_ID\"]: \n",
    "        for player in players_dict:\n",
    "            if player['id'] == player_id:\n",
    "                players_list.append(player['full_name'])\n",
    "                \n",
    "    df[\"PLAYER_NAME\"] = players_list\n",
    "    \n",
    "    df[\"TEAM_A\"] = df[\"MATCHUP\"].apply(lambda x: re.split('@|vs.', x)[0].strip())\n",
    "    df[\"TEAM_B\"] = df[\"MATCHUP\"].apply(lambda x: re.split('@|vs.', x)[1].strip())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction seasons\n",
    "seasons = dfr.reset_index()[\"SEASON\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = prep_winloss_data(dfwl, seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_dict = teams.get_teams()\n",
    "    \n",
    "team_namesA = []\n",
    "for team in dfc[\"TEAM_A\"]:\n",
    "    found = False\n",
    "    for team_dict in teams_dict:\n",
    "        if team_dict['abbreviation'] == team:\n",
    "            team_namesA.append(team_dict['full_name'])\n",
    "            found = True\n",
    "    if not found:\n",
    "        team_namesA.append(\"\")\n",
    "    \n",
    "dfc[\"TEAM_A_NAME\"]= team_namesA\n",
    "                \n",
    "team_namesB = []\n",
    "for team in dfc[\"TEAM_B\"]:\n",
    "    found = False\n",
    "    for team_dict in teams_dict:\n",
    "        if team_dict['abbreviation'] == team:\n",
    "            team_namesB.append(team_dict['full_name'])\n",
    "            found = True\n",
    "    if not found:\n",
    "        team_namesB.append(\"\")\n",
    "                \n",
    "dfc[\"TEAM_B_NAME\"] = team_namesB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_vars = ['FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', \n",
    "                   'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc_selected = dfc[dfc[\"SEASON_ID\"] == '2018-19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc_interested_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_player_data(dfc, wpdf, seasons):    \n",
    "    tojoindf = pd.DataFrame()\n",
    "    for i in range(len(dfc)):\n",
    "        current_season = dfc.iloc[i][\"SEASON_ID\"]\n",
    "        prev_season = seasons[seasons.index(current_season)-1]\n",
    "        \n",
    "        teamA = dfc.iloc[i][\"TEAM_A_NAME\"]\n",
    "        teamB = dfc.iloc[i][\"TEAM_B_NAME\"]\n",
    "    \n",
    "        teamA_data = wpdf[(wpdf[\"GROUP_VALUE\"] == current_season) & (wpdf[\"TEAM_NAME\"] == teamA)]\n",
    "        teamB_data = wpdf[(wpdf[\"GROUP_VALUE\"] == current_season) & (wpdf[\"TEAM_NAME\"] == teamB)]\n",
    "        \n",
    "        teamA_data = teamA_data[teamA_data.columns[7:-1]]\n",
    "        teamB_data = teamB_data[teamB_data.columns[7:-1]]\n",
    "        \n",
    "        new_colsA = []\n",
    "        for col in teamA_data.columns:\n",
    "            new_colsA.append(col + \"_A\")\n",
    "        \n",
    "        new_colsB = []\n",
    "        for col in teamB_data.columns:\n",
    "            new_colsB.append(col + \"_B\")\n",
    "            \n",
    "        teamA_data.columns = new_colsA\n",
    "        teamB_data.columns = new_colsB \n",
    "        \n",
    "        merged = pd.concat([teamA_data, teamB_data], axis=1)\n",
    "        \n",
    "        \n",
    "        return merged\n",
    "        \n",
    "        X = []\n",
    "        for col in merged.columns:\n",
    "            if col.endswith(prev_season):\n",
    "                X.append(col)\n",
    "                \n",
    "        merged[X]\n",
    "        \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=inject_player_data(dfc, wpdf, seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcg = dfc.groupby([\"SEASON_ID\", \"TEAM_A_NAME\", \"PLAYER_NAME\"])[interested_vars].mean()\n",
    "dfcg[\"MIN\"] = dfc.groupby([\"SEASON_ID\", \"TEAM_A_NAME\", \"PLAYER_NAME\"])['MIN'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
